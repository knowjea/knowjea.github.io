---
layout: post
title: "Kafka, Prometheus, Grafana"
author: "Know jea"
categories: 
tags: [Kafka, Prometheus, 토비의 Grafana]
comments: true
---


**Prometheus**가 **Kafka**의 다양한 정보를 긁어 내고 **Prometheus**를 데이터 소스로 사용하여 **Grafana**에서 표현하자.

### Prometheus가 Kafka의 정보를 긁을 수 있도록 에이전트를 Kafka에 연결

- Kafka 정보를 추출해내기 위해 이 글에서는 두 가지를 사용

1. **JMX exporter** ([https://github.com/prometheus/jmx_exporter](https://github.com/prometheus/jmx_exporter))
    - JMX 기반으로 모니터링하여 데이터를 읽어 Prometheus가 정보를 긁어갈 수 있도록 HTTP 방식으로 표현
    - 모니터링 하기 위한 java 어플리케이션에 jvm옵션을 주어 에이전트를 붙이는 방식이므로, 새롭게 추가할 경우, 어플리케이션을 재기동해야하는 단점 존재

    - **JMX exporter 설치**

    ```bash
    # JMX exporter jar 다운
    wget https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.12.0/jmx_prometheus_javaagent-0.12.0.jar

    # JMX exporter Kafka 설정 다운
    wget https://raw.githubusercontent.com/prometheus/jmx_exporter/master/example_configs/kafka-2_0_0.yml
    ```

    - **Kafka에 JMX exporter 설정**

    ```bash
    // kafka-server-start.sh 파일에 아래 옵션 추가

    // 7071은 정보를 표현할 http 포트번호
    export KAFKA_OPTS="-javaagent:${JMX_HOME}/jmx_prometheus_javaagent-0.12.0.jar=7071:${JMX_HOME}/kafka-2_0_0.yml"
    ```

    - 카프카 재실행 후, [http://localhost:7071/metrics](http://localhost:7071/metrics) 접속시 아래와 같이 정보가 생성되면 성공

        ![test/Untitled.png](test/Untitled.png)

2. **kafka_exporter** ([https://github.com/danielqsj/kafka_exporter](https://github.com/danielqsj/kafka_exporter))
    - 파티션이나 토픽에 대해 좀더 많은 정보를 생성해주는 에이전트
    - Kafka를 재기동하지 않고도 가능

    - **kafka_exporter 설치**

        ```bash
        # kafka_exporter 압축파일 다운
        wget https://github.com/danielqsj/kafka_exporter/releases https://github.com/danielqsj/kafka_exporter/releases/download/v1.2.0/kafka_exporter-1.2.0.linux-amd64.tar.gz

        # 압축 해제
        tar -zxvf kafka_exporter-1.2.0.linux-amd64.tar.gz
        ```

    - **kafka_exporter 실행**

        ```bash
        # 1대 브로커 기준, 각각의 IP와 포트번호 입력
        ./kafka_exporter --kafka.server=server1:9092
        ```

    - [http://localhost:9308/metrics](http://localhost:9308/metrics) 접속시 아래와 같이 정보가 생성되면 성공

        ![Kafka,%20Prometheus,%20Grafana%206385dfd6f74d40e49bb1cb4601f151ed/Untitled%201.png](Kafka,%20Prometheus,%20Grafana%206385dfd6f74d40e49bb1cb4601f151ed/Untitled%201.png)

### Prometheus 설치 및 Kafka 정보 Scraping

- 위에서 만든 두 스크래핑 데이터를 Prometheus가 읽도록 설치 및 설정

- **Prometheus 설치**

    ```bash
    # Prometheus 압축파일 다운
    wget https://github.com/prometheus/prometheus/releases/download/v2.2.1/prometheus-2.2.1.linux-amd64.tar.gz

    # 압축 해제
    tar -zxvf prometheus-2.2.1.linux-amd64.tar.gz
    ```

- **Prometheus 설정 : prometheus.yml**
    - scrape_timeout 설정을 추가함. **kafka_exporter** 스크래핑시  디폴트 타임아웃 시간인 10초를 넘어가 **context deadline exceeded** 에러가 발생하여 30초로 변경
    - **targets**에 각가의 에이전트 호스트:포트번호를 입력 ****

    ```yaml

    # my global config
    global:
      scrape_interval:     30s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
      evaluation_interval: 30s # Evaluate rules every 15 seconds. The default is every 1 minute.
      scrape_timeout: 30s

    # Alertmanager configuration
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          # - alertmanager:9093

    # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
    rule_files:
      # - "first_rules.yml"
      # - "second_rules.yml"

    # A scrape configuration containing exactly one endpoint to scrape:
    # Here it's Prometheus itself.
    scrape_configs:
      # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
      - job_name: 'kafka'

        # metrics_path defaults to '/metrics'
        # scheme defaults to 'http'.

        static_configs:
          - targets:
            - 'localhost:9308' # kafka_exporter
            - 'localhost:7071' # JMX exporter
    ```

- **Prometheus 실행**

    ```bash
    # 실행
    ./prometheus
    ```

- [http://localhost:9090/graph](http://localhost:9090/graph) 접속시 아래와 같이 접속되면 성공

    ![Kafka,%20Prometheus,%20Grafana%206385dfd6f74d40e49bb1cb4601f151ed/Untitled%202.png](Kafka,%20Prometheus,%20Grafana%206385dfd6f74d40e49bb1cb4601f151ed/Untitled%202.png)

- Status → Targets에 아래와 같이 모두 Up상태이면 현재 스크래핑을 정상적으로 동작하고 있음을 의미.

    ![Kafka,%20Prometheus,%20Grafana%206385dfd6f74d40e49bb1cb4601f151ed/Untitled%203.png](Kafka,%20Prometheus,%20Grafana%206385dfd6f74d40e49bb1cb4601f151ed/Untitled%203.png)

- 에러가 발생할 경우, **Error** 탭에 에러메시지 생성됨

### Grafana에 Prometheus 데이터소스 설정 및 대시보드 만들기

- Grafana 설치는 이 글을 참조

- **Data Sources에 Prometheus 추가**

    ![Kafka,%20Prometheus,%20Grafana%206385dfd6f74d40e49bb1cb4601f151ed/Untitled%204.png](Kafka,%20Prometheus,%20Grafana%206385dfd6f74d40e49bb1cb4601f151ed/Untitled%204.png)

- **대시보드 만들기**
    - 직접 스크래핑 데이터를 가지고 차트를 만들어도 됨.
    - 다만, 현재는 스크래핑 데이터의 의미도 알지 못하고, 테스트이기 때문에 기존에 만들어져있는 대시보드를 import
    - [https://grafana.com/grafana/dashboards](https://grafana.com/grafana/dashboards) 에서 kafka 검색하여 원하는 대시보드 import하여 커스터마이징 하기.
    - 스크래핑 데이터가 다른 대시보드들도 많기 때문에, 현재 kafka_exporter와 JMX exporter로만 가능한 대시보드를 찾아서 사용

    - [https://grafana.com/grafana/dashboards/721](https://grafana.com/grafana/dashboards/721)
        - 가장 심플한 대시보드이며, JMX exporter 데이터로만으로 가능

        ![Kafka,%20Prometheus,%20Grafana%206385dfd6f74d40e49bb1cb4601f151ed/Untitled%205.png](Kafka,%20Prometheus,%20Grafana%206385dfd6f74d40e49bb1cb4601f151ed/Untitled%205.png)

    - [https://grafana.com/grafana/dashboards/7589](https://grafana.com/grafana/dashboards/7589)
        - kafka_exporter 데이터로 만든 대시보드.
        - 글쓴이는 consumer 부분의 정보는 존재하지 않아서 표현 불가능
        - 다른 세 개의 차트는  #{topic}과 #{instance}에서 #{topic}은 제거하고, #{instnace}에는 실제 IP:포트번호를 입력하니 표현 됨

        ![Kafka,%20Prometheus,%20Grafana%206385dfd6f74d40e49bb1cb4601f151ed/Untitled%206.png](Kafka,%20Prometheus,%20Grafana%206385dfd6f74d40e49bb1cb4601f151ed/Untitled%206.png)